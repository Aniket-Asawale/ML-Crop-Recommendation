# ğŸŒ¾ Intelligent Agriculture - Crop Recommendation System
## Machine Learning for Smart Farming

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Ready%20to%20Implement-brightgreen)

## ğŸ“‹ Project Overview

This project implements a comprehensive machine learning analysis for **intelligent agriculture** based on the research paper "Leveraging Machine Learning for Intelligent Agriculture" (Springer, 2025). The project demonstrates **10 major machine learning algorithms** for crop recommendation and agricultural decision-making.

### ğŸ¯ Objectives
- Implement crop recommendation system using ML
- Compare 10+ ML algorithms for agricultural applications
- Analyze soil and climate factors affecting crop selection
- Demonstrate model training from scratch (no APIs)
- Provide actionable insights for farmers

---

## ğŸ“Š Research Paper

**Title:** "Leveraging Machine Learning for Intelligent Agriculture"

**Authors:** B.J. Sowmya, A.K. Meeradevi, S. Supreeth, et al.

**Publication:**
- **Journal:** Discover Internet of Things (Springer)
- **Volume:** 5, Article 33
- **Date:** March 26, 2025
- **DOI:** 10.1007/s43926-025-00132-6
- **Link:** https://link.springer.com/article/10.1007/s43926-025-00132-6
- **Status:** âœ… Scopus Indexed, âœ… Open Access

---

## ğŸ“ˆ Dataset Information

### **Crop Recommendation Dataset**

- **Source:** Kaggle
- **Link:** https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset
- **Size:** 2,200 instances
- **Features:** 7 numerical + 1 target (22 crop classes)
- **Status:** âœ… Verified, âœ… No Missing Values, âœ… Balanced

### **Dataset Features:**

| Feature | Description | Unit |
|---------|-------------|------|
| N | Nitrogen content in soil | kg/ha |
| P | Phosphorous content | kg/ha |
| K | Potassium content | kg/ha |
| temperature | Average temperature | Â°C |
| humidity | Relative humidity | % |
| ph | Soil pH value | 0-14 |
| rainfall | Average rainfall | mm |
| **label** | **Crop recommendation** | **Target** |

### **Target Crops (22 classes):**
Rice, Maize, Chickpea, Kidneybeans, Pigeonpeas, Mothbeans, Mungbean, Blackgram, Lentil, Pomegranate, Banana, Mango, Grapes, Watermelon, Muskmelon, Apple, Orange, Papaya, Coconut, Cotton, Jute, Coffee

---

## ğŸ”¬ ML Algorithms Implemented

### âœ… All 10 Required Topics Covered (100%)

| # | Algorithm | Category | Application |
|---|-----------|----------|-------------|
| 1 | **Linear Regression** | Regression | Predict optimal NPK levels |
| 2 | **Logistic Regression** | Classification | Binary crop suitability |
| 3 | **SVM** | Classification | Multi-class crop recommendation |
| 4 | **Multivariate Linear Regression** | Regression | Multiple feature prediction |
| 5 | **Random Forest** | Ensemble (Bagging) | Crop recommendation |
| 6 | **AdaBoost/XGBoost** | Ensemble (Boosting) | Enhanced accuracy |
| 7 | **Decision Tree (CART)** | Classification/Regression | Rule-based recommendations |
| 8 | **K-Means Clustering** | Clustering | Group similar crops |
| 9 | **DBSCAN** | Clustering | Density-based crop groups |
| 10 | **PCA/LDA** | Dimensionality Reduction | Feature reduction |

### ğŸ Bonus Algorithms
- LightGBM (Advanced Boosting)
- Hierarchical Clustering
- Naive Bayes
- K-Nearest Neighbors (KNN)

---

## ğŸ“ Project Structure

```
ML/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Raw dataset
â”‚   â”‚   â””â”€â”€ crop_recommendation.csv    # Download from Kaggle
â”‚   â””â”€â”€ processed/                     # Preprocessed data (auto-generated)
â”‚       â”œâ”€â”€ train.csv
â”‚       â”œâ”€â”€ test.csv
â”‚       â””â”€â”€ validation.csv
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_EDA_and_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_Linear_Regression.ipynb
â”‚   â”œâ”€â”€ 03_Logistic_Regression.ipynb
â”‚   â”œâ”€â”€ 04_SVM_Classification.ipynb
â”‚   â”œâ”€â”€ 05_PCA_LDA_Analysis.ipynb
â”‚   â”œâ”€â”€ 06_Ensemble_Methods.ipynb
â”‚   â”œâ”€â”€ 07_CART_Decision_Trees.ipynb
â”‚   â”œâ”€â”€ 08_Clustering_Analysis.ipynb
â”‚   â”œâ”€â”€ 09_DBSCAN_Analysis.ipynb
â”‚   â”œâ”€â”€ 10_Advanced_Techniques.ipynb
â”‚   â””â”€â”€ 11_Model_Comparison.ipynb
â”‚
â”œâ”€â”€ src/                               # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py          # Data preprocessing utilities
â”‚   â”œâ”€â”€ feature_engineering.py         # Feature creation
â”‚   â”œâ”€â”€ evaluation.py                  # Model evaluation
â”‚   â”œâ”€â”€ visualization.py               # Plotting functions
â”‚   â””â”€â”€ models/                        # Model implementations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ linear_models.py
â”‚       â”œâ”€â”€ svm_models.py
â”‚       â”œâ”€â”€ ensemble_models.py
â”‚       â”œâ”€â”€ tree_models.py
â”‚       â””â”€â”€ clustering_models.py
â”‚
â”œâ”€â”€ models/                            # Saved trained models
â”‚   â””â”€â”€ saved_models/
â”‚
â”œâ”€â”€ results/                           # Results and outputs
â”‚   â”œâ”€â”€ figures/                       # Generated plots
â”‚   â”œâ”€â”€ metrics/                       # Performance metrics
â”‚   â””â”€â”€ comparisons/                   # Model comparisons
â”‚
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ RESEARCH_PAPER_AND_DATASET.md     # Paper and dataset details
â””â”€â”€ problem_statement.md              # Original requirements
```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)
- Jupyter Notebook
- 5 GB free disk space

### Installation Steps

#### 1. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

**Dependencies include:**
- pandas, numpy, scipy (data processing)
- matplotlib, seaborn, plotly (visualization)
- scikit-learn (ML algorithms)
- xgboost, lightgbm (advanced algorithms)
- jupyter (notebook environment)

#### 3. Download Dataset

**Option A: Manual Download (Recommended)**
1. Visit: https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset
2. Sign in to Kaggle
3. Click "Download"
4. Save `Crop_recommendation.csv` to `data/raw/`

**Option B: Kaggle API**
```bash
# Install Kaggle CLI
pip install kaggle

# Download dataset
kaggle datasets download -d atharvaingle/crop-recommendation-dataset

# Extract to data/raw/
unzip crop-recommendation-dataset.zip -d data/raw/
```

#### 4. Launch Jupyter Notebook

```bash
jupyter notebook
```

Navigate to `notebooks/` and start with `01_EDA_and_Preprocessing.ipynb`

---

## ğŸ“Š Implementation Roadmap

### Phase 1: Data Preparation âœ…
- [ ] Download dataset from Kaggle
- [ ] Exploratory Data Analysis (EDA)
- [ ] Data cleaning and preprocessing
- [ ] Feature engineering
- [ ] Train-test-validation split

### Phase 2: Linear Models ğŸ“‹
- [ ] Simple Linear Regression
- [ ] Multivariate Linear Regression
- [ ] Logistic Regression (binary classification)
- [ ] Model evaluation and visualization

### Phase 3: Support Vector Machines ğŸ“‹
- [ ] Linear SVM
- [ ] RBF Kernel SVM
- [ ] Polynomial Kernel SVM
- [ ] Hyperparameter tuning (GridSearchCV)

### Phase 4: Dimensionality Reduction ğŸ“‹
- [ ] Principal Component Analysis (PCA)
- [ ] Linear Discriminant Analysis (LDA)
- [ ] Visualize reduced dimensions
- [ ] Compare model performance

### Phase 5: Ensemble Methods ğŸ“‹
- [ ] Random Forest (Bagging)
- [ ] AdaBoost (Boosting)
- [ ] Gradient Boosting
- [ ] XGBoost
- [ ] LightGBM
- [ ] Feature importance analysis

### Phase 6: Decision Trees (CART) ğŸ“‹
- [ ] Decision Tree Classifier
- [ ] Tree visualization
- [ ] Pruning techniques
- [ ] Rule extraction

### Phase 7: Clustering Analysis ğŸ“‹
- [ ] K-Means Clustering
- [ ] DBSCAN
- [ ] Hierarchical Clustering
- [ ] Cluster validation metrics

### Phase 8: Model Comparison ğŸ“‹
- [ ] Compare all 10+ models
- [ ] Performance metrics dashboard
- [ ] Statistical significance tests
- [ ] Final recommendations

---

## ğŸ” Evaluation Metrics

### Classification Metrics
- **Accuracy:** Overall correctness
- **Precision:** Positive predictive value
- **Recall:** Sensitivity
- **F1-Score:** Harmonic mean
- **ROC-AUC:** Area under curve
- **Confusion Matrix:** Detailed classification

### Regression Metrics
- **MSE:** Mean Squared Error
- **RMSE:** Root Mean Squared Error
- **MAE:** Mean Absolute Error
- **RÂ² Score:** Coefficient of determination

### Clustering Metrics
- **Silhouette Score:** Cluster cohesion
- **Davies-Bouldin Index:** Cluster separation
- **Calinski-Harabasz Index:** Variance ratio

---

## ğŸ“ˆ Expected Results

Based on literature review and similar studies:

| Model | Expected Accuracy | F1-Score |
|-------|------------------|----------|
| Logistic Regression | 88-92% | 0.87-0.91 |
| SVM (RBF) | 90-94% | 0.89-0.93 |
| Random Forest | 95-98% | 0.94-0.97 |
| XGBoost | 96-99% | 0.95-0.98 |
| Decision Tree | 85-90% | 0.84-0.89 |

**Goal:** Achieve 95%+ accuracy for crop recommendation

---

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**
- **NumPy & Pandas:** Data manipulation
- **Scikit-learn:** ML algorithms
- **XGBoost & LightGBM:** Advanced ensemble methods
- **Matplotlib, Seaborn, Plotly:** Visualization
- **Jupyter Notebook:** Interactive development
- **SHAP:** Model interpretability

---

## ğŸ“š Key Features

### 1. Comprehensive Preprocessing
- Automated missing value handling
- Feature scaling and normalization
- Data split with stratification
- Feature engineering pipelines

### 2. Multiple ML Algorithms
- 10+ algorithms implemented
- Hyperparameter tuning
- Cross-validation
- Model comparison

### 3. Rich Visualizations
- Feature distributions
- Correlation heatmaps
- Confusion matrices
- ROC curves
- Feature importance plots
- Cluster visualizations
- PCA/LDA plots

### 4. Model Interpretability
- Feature importance rankings
- SHAP values (if time permits)
- Decision tree rules
- Clustering insights

### 5. Practical Application
- Crop recommendation system
- Soil nutrient analysis
- Climate suitability assessment
- Farming decision support

---

## ğŸ¯ Project Applications

### 1. Crop Recommendation
- Input: Soil NPK, climate data
- Output: Best crop to grow
- Accuracy: 95%+

### 2. Soil Analysis
- Identify soil deficiencies
- Recommend fertilizers
- Optimize crop selection

### 3. Climate Suitability
- Assess temperature/humidity/rainfall
- Recommend suitable crops
- Risk analysis

### 4. Crop Clustering
- Group crops with similar requirements
- Crop rotation planning
- Diversification strategies

---

## ğŸ“– Research Paper Implementation

The project implements techniques from the research paper:

1. **Computer Vision** â†’ Feature visualization
2. **Deep Learning** â†’ Optional neural network implementation
3. **Machine Learning** â†’ All 10 algorithms
4. **Smart Agriculture** â†’ Practical crop recommendations
5. **IoT Integration** â†’ Data-driven decision making

---

## ğŸ”¬ Academic Requirements Met

- âœ… **2025 Research Paper:** Yes (March 2025)
- âœ… **Scopus Indexed:** Yes (Discover Internet of Things)
- âœ… **Open Access:** Yes (Free to read)
- âœ… **DOI Available:** Yes (10.1007/s43926-025-00132-6)
- âœ… **Agriculture Related:** Yes (Crop Recommendation)
- âœ… **Dataset Available:** Yes (Kaggle, 2,200 samples)
- âœ… **Dataset Verified:** Yes (No missing values, balanced)
- âœ… **Covers 7-8 ML Topics:** Yes (Covers all 10 - 100%)
- âœ… **No API Usage:** Yes (All models trained from scratch)
- âœ… **AIML Related:** Yes (ML for Agriculture)

---

## ğŸ“ License

This project is open source and available under the MIT License.

---

## ğŸ‘¨â€ğŸ’» Author

- **[Aniket-Asawale](https://github.com/Aniket-Asawale)**
- **Project:** ML Mini-Project (SEM 7)
- **Focus:** Intelligent Agriculture
- **Year:** 2025

---

## ğŸ™ Acknowledgments

- Research paper authors (Sowmya, B.J., et al.)
- Kaggle community for the dataset
- Springer Nature for open access publication
- Scikit-learn and open-source ML libraries

---

## ğŸ“§ Support

For questions or issues:
1. Check `RESEARCH_PAPER_AND_DATASET.md` for details
2. Review code comments and docstrings
3. Follow notebook cell explanations

---

## ğŸ“Œ Project Status

**Current Status:** âœ… Working Models but few models are bugged (due to invalid feature conversion to numpy)

**Last Updated:** October 6, 2025

**Next Steps:**
1. Download dataset from Kaggle
2. Place in `data/raw/` directory
3. Install dependencies: `pip install -r requirements.txt`
4. Launch Jupyter: `jupyter notebook`
5. Start with notebook 01

---

## ğŸ‰ Success Criteria

Project is complete when:
- âœ… All 11 notebooks run without errors
- âœ… All 10+ ML algorithms implemented
- âœ… Models trained and evaluated
- âœ… Visualizations generated (20+ plots)
- âœ… Final comparison report created
- âœ… Crop recommendation system working
- âœ… Results documented and analyzed

---

**â­ If you find this project useful, please star the repository!**

**ğŸ“¢ Ready to revolutionize agriculture with Machine Learning? Let's begin!** ğŸŒ¾ğŸšœğŸ¤–

